<br>
<br>
<h1>Unveiling High-level Discriminant Harmonic Features of Musical Style in the Tonal Interval Space</h1>
<blockquote>
<p>This is a supplementary material to the submission of the paper &quot;Unveiling High-level Discriminant Harmonic Features of Musical Style in the Tonal Interval Space&quot; to ICMPC 2021 conference.</p>
</blockquote>
<hr>
<p>Style is one of the most prominent musical traits in distinguishing historical times, composers, musicians, sonic texture, emotion, and genre. In recent years, the automatic recognition and synthesis of musical styles have been extensively pursued. Most of the work focuses on low-level perceptual characteristics that do not reflect the hierarchical nature of harmony, namely the temporal structure of the harmonic progressions. In this project, we aim to unveil musicological and perceptually inspired harmonic descriptors in the Tonal Interval Space that best discriminate musical eras within the Western classical tradition. Descriptors that account for multiple time scales of the vertical and horizontal harmonic structure are considered, which in harmonic terms can be understood as harmonic quality and progressions (notably including voice leading). The selection of representative discriminant harmonic features is data-driven and adopts the cross-era dataset, which includes 200 tracks per representative Western historical music period (Baroque, Classical, Romantic, and Modern), and two instrumentations (orchestra and piano).</p>
<h2>Descriptors</h2>
<p>Each musical track is represented by a collection of harmonic descriptors driven computed as the time-varying descriptive statistics per track. We focused on four highly robust statistics: median (med) as a measure of central tendency; interquartile range (IQR) as a measure of the variability of the descriptor data distribution. Audio frames from which we compute Tonal Interval Vectors derive from NNLS chromas (window size of 8192 samples and a step size of 4410 samples, assuming a sample rate of 44.100 kHz).</p>
<p>Departing from a chromagram representation, <img src="https://i.upmath.me/svg/C" alt="C" />, we compute a 12-dimensional $T(k)$ as the $L_1$ normalized discrete Fourier transform (DFT), such that:</p>
<p align="center"><img align="center" src="https://i.upmath.me/svg/%0AT(k)%3D%20w_%7B%5Cstar%7D(k)%20%5Csum_%7Bn%3D0%7D%5E%7BN-1%7D%20%5Cbar%7BC%7D(m)%20e%5E%5Cfrac%7B-j2%5Cpi%20%20km%7D%7BM%7D%20%5C%2C%20%2C%0Ak%20%5Cin%20%20%5Cmathbb%7BZ%7D%20%5Cquad%20%5Ctextrm%7Bwith%7D%20%5Cquad%20%20%5Cbar%7BC%7D(m)%3D%5Cfrac%7BC(m)%7D%7B%5Csum_%7Bn%3D0%7D%5E%7BM-1%7DC(m)%7D%0A" alt="
T(k)= w_{\star}(k) \sum_{n=0}^{N-1} \bar{C}(m) e^\frac{-j2\pi  km}{M} \, ,
k \in  \mathbb{Z} \quad \textrm{with} \quad  \bar{C}(m)=\frac{C(m)}{\sum_{n=0}^{M-1}C(m)}
" /></p>
<p>where <img src="https://i.upmath.me/svg/M%3D12" alt="M=12" /> is the dimension of the chromagram, <img src="https://i.upmath.me/svg/C" alt="C" />; <img src="https://i.upmath.me/svg/k" alt="k" /> is set to <img src="https://i.upmath.me/svg/1%20%5Cleq%20k%20%5Cleq%206" alt="1 \leq k \leq 6" /> since the remaining coefficients are symmetric; <img src="https://i.upmath.me/svg/T(k)" alt="T(k)" /> uses <img src="https://i.upmath.me/svg/%5Cbar%7BC%7D(m)" alt="\bar{C}(m)" /> which is <img src="https://i.upmath.me/svg/C(m)" alt="C(m)" /> normalized by the DC component <img src="https://i.upmath.me/svg/T(0)%3D%5Csum_%7Bn%3D0%7D%5E%7BM-1%7DC(m)" alt="T(0)=\sum_{n=0}^{M-1}C(m)" /> to allow the representation and comparison of different hierarchical levels of tonal pitch; and <img src="https://i.upmath.me/svg/w_%7B%5Cstar%7D(k)" alt="w_{\star}(k)" /> are weights which regulate the importance of each coefficient (or interpreted musical interval) in <img src="https://i.upmath.me/svg/T(k)" alt="T(k)" />. The weights <img src="https://i.upmath.me/svg/w_a(k)%3D%5C%7B3%2C%208%2C%2011.5%2C%2015%2C%2014.5%2C%207.5%5C%7D" alt="w_a(k)=\{3, 8, 11.5, 15, 14.5, 7.5\}" /> are used, optimized for musical audio, result from empirical ratings of dyads consonance, which adjust the contribution of each dimension <img src="https://i.upmath.me/svg/k" alt="k" /> of the space (or interpreted musical interval), making it a perceptually relevant space in comparison to its non-weighted version.</p>
<p>The interactive box plot below presents the harmonic descriptorsâ€™ descriptive statistics harmonic per era and instrumentation. To isolate particular descriptors, double-click in the plot legends. Single clicks add/remove given descriptors from the plot.</p>
<p>{% include boxplot.html %}</p>
<p>Next, we list the full set of harmonic descriptors adopted in the study and detail their mathematical definition and musical interpretation.</p>
<ul>
<li>
<p><strong>Dissonance (diss)</strong>:  provides a perceptually inspired indicator of dissonance, as the normalized as a weighted magnitude of TIV magnitudes subtracted from unity <img src="https://i.upmath.me/svg/1%20-%20%5Cfrac%7B%5C%7C%20T(k)%7D%7B%20%5C%7Cw_*(k)%5C%7C%7D" alt="1 - \frac{\| T(k)}{ \|w_*(k)\|}" />, where w_* can assume <img src="https://i.upmath.me/svg/w_a(k)%20%3D%20%7B3%2C%208%2C%2011.5%2C%2015%2C%2014.5%2C%207.5%7D" alt="w_a(k) = {3, 8, 11.5, 15, 14.5, 7.5}" /> for audio input chromas and <img src="https://i.upmath.me/svg/w_s(k)%20%3D%20%7B2%2C%2011%2C%2017%2C%2016%2C%2019%2C%207%7D" alt="w_s(k) = {2, 11, 17, 16, 19, 7}" /> for symbolic pitch class (pc) set. The descriptor output ranges from [0,1], where 0 corresponds to a highly dissonant sound (12 pitch class cluster) and 1 to a very consonant single pitch class.</p>
</li>
<li>
<p><strong>Chromaticity (chromatic):</strong> indicates the level of the chromatic quality of a given chroma or pc set as the magnitude of the TIV in the chromatic pitch circle. It is computed as the magnitude of the T(2) normalized to unity (range [0-1]), $$\frac{|| T(1)||}{w_*(1)}.</p>
</li>
<li>
<p><strong>Dyadicity (dyad):</strong> indicates the level to which a given pc set or sonority embeds the tritone quality, expressive for chords consisting of stacked perfect and augmented fourths. It is computed as the magnitude of the T(2) normalized to unity (range [0-1]), <img src="https://i.upmath.me/svg/%5Cfrac%7B%5C%7C%7C%20T(2)%5C%7C%7C%7D%7Bw_*(2)%7D" alt="\frac{\|| T(2)\||}{w_*(2)}" />.</p>
</li>
<li>
<p><strong>Triadicity (triad):</strong> indicates the level to which a given pc set or sonority consists of major and minor triads. It is computed as the magnitude of the T(3) normalized to unity (range [0-1]), <img src="https://i.upmath.me/svg/%5Cfrac%7B%5C%7C%7C%20T(3)%5C%7C%7C%7D%7Bw_*(3)%7D" alt="\frac{\|| T(3)\||}{w_*(3)}" />.</p>
</li>
<li>
<p><strong>Diminished Quality (dim):</strong> indicates the level to which a given pc set or sonority complies to a diminished seventh chord. It is computed as the magnitude of the T(4) normalized to unity (range [0-1]), <img src="https://i.upmath.me/svg/%5Cfrac%7B%5C%7C%7C%20T(4)%5C%7C%7C%7D%7Bw_*(4)%7D" alt="\frac{\|| T(4)\||}{w_*(4)}" />.</p>
</li>
<li>
<p><strong>Diatonicity (diatonic):</strong> indicates the level of diatonicity of a given chroma or pc. It is computed as the magnitude of the T(5) normalized to unity (range [0-1]), <img src="https://i.upmath.me/svg/%5Cfrac%7B%5C%7C%7C%20T(5)%5C%7C%7C%7D%7Bw_*(5)%7D" alt="\frac{\|| T(5)\||}{w_*(5)}" />.</p>
</li>
<li>
<p><strong>Whole toneness (wholeTone):</strong> indicates the level to which a given pc set or sonority complies to a whole-tone set. It is computed as the magnitude of the T(6) normalized to unity (range [0-1]), <img src="https://i.upmath.me/svg/%5Cfrac%7B%5C%7C%7C%20T(6)%5C%7C%7C%7D%7Bw_*(6)%7D" alt="\frac{\|| T(6)\||}{w_*(6)}" />.</p>
</li>
<li>
<p><strong>HCDF peaks:</strong> result from the magnitude of the peaks in the Harmonic Change Detection Function (HCDF) in the Tonal Interval Space. Larger magnitude values indicate harmonic changes from greater perceptual distance across two sequential chords.</p>
</li>
<li>
<p><strong>Harmonic Rhythm (hRhythm):</strong> is computed as the inter peak interval (in frames) from the HCDF, thus providing an indicator of the harmonic rhythm.</p>
</li>
<li>
<p><strong>Tonal Dispersion (eucTDispersion and cosTDispersion):</strong> It measures the consonance (eucTDispersion) or the perceptual proximity (cosTDispersion) of each frame to the tonal center. Consonance is represented as the euclidean distance between two Tonal Interval Vectors. Due to the symmetry of the Tonal Interval Space, complementary intervals and transposition share the same level of consonance. Tonal center is computed as the mean of every TIV musical piece.</p>
</li>
<li>
<p><strong>Tonal Relatedness (eucTIV and cosTIV)</strong>: it measures the consonance (eucTIV) and perceptual proximity (cosTIV) progression frame by frame. Multi-resolution TIVs give significant comparisons of the harmonic time perspectives evolution.</p>
</li>
</ul>
<h2>Descriptors Analysis</h2>
<p>To assess the intercorrelations among harmonic audio descriptors and the number of groups of independent descriptors, we modeled the between-descriptor distances using two distance models: hierarchical clustering and metric MDS. Distance models are computed from a square matrix denoting the absolute correlation distance across all harmonic audio descriptors.</p>
<img class="img-responsive center-block" src="/assets/img/dendogram.png" style="max-width: 87%;">
<img class="img-responsive center-block" src="/assets/img/mds.png">
<p><strong>Feature importance:</strong> A cross validated logistic regression is performed to rank the importance of each feature to distinguis clasical music historical periods.
<img class="img-responsive center-block" src="/assets/img/relative_feature_importance.png" style="max-width: 60%;"></p>