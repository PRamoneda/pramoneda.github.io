<script src="https://i.upmath.me/latex.js"></script>
<br>
<br>
<h1>Unveiling High-level Discriminant Harmonic Features of Musical Style in the Tonal Interval Space</h1>
<blockquote>
<p>This is a supplementary material to the submission of the paper &quot;Unveiling High-level Discriminant Harmonic Features of Musical Style in the Tonal Interval Space&quot; to the International Conference on Music Perception and Cognition (ICMPC) 2021 conference.</p>
</blockquote>
<hr>
<p>Style is one of the most prominent musical traits in distinguishing historical times, composers, musicians, sonic texture, emotion, and genre. In recent years, the automatic recognition and synthesis of musical styles have been extensively pursued. Most of the work focuses on low-level perceptual characteristics that do not reflect the hierarchical nature of harmony, namely the temporal structure of the harmonic progressions. In this project, we aim to unveil musicological and perceptually inspired harmonic descriptors in the Tonal Interval Space that best discriminate musical eras within the Western classical tradition. Descriptors that account for multiple time scales of the vertical and horizontal harmonic structure are considered, which in harmonic terms can be understood as harmonic quality and progressions (notably including voice leading). The selection of representative discriminant harmonic features is data-driven and adopts the cross-era dataset, which includes 200 tracks per representative Western historical music period (Baroque, Classical, Romantic, and Modern), and two instrumentations (orchestra and piano).</p>
<h2>Descriptors</h2>
<p>Each musical track is represented by a collection of harmonic descriptors  computed as time-varying descriptive statistics. We focused on highly robust statistics: median (med) as a measure of central tendency and  interquartile range (IQR) as a measure of the variability of the descriptor data distribution. Audio frames from which we compute Tonal Interval Vectors derive from NNLS chromagrams (window size of 8192 samples and a step size of 4410 samples, assuming a sample rate of 44.100 kHz).</p>
<p>Descriptors derive from 12-dimensional Tonal Interval Vector space, $$T(k)$$, computed as the DFT of 12-element chroma vectors, $$C$$, such that:</p>
<p>$$
T(k)= w_a(k) \sum_{n=0}^{N-1} \bar{C}(m) e^\frac{-j2\pi  km}{M} \, ,
k \in  \mathbb{Z} \quad \textrm{with} \quad  \bar{C}(m)=\frac{C(m)}{\sum_{n=0}^{M-1}C(m)}
$$</p>
<p>where $$M=12$$ is the dimension of the chromagram, $$C$$; $$k$$ is set to $$1 \leq k \leq 6$$ since the remaining coefficients are symmetric; $$T(k)$$ uses $$\bar{C}(m)$$ which is $$C(m)$$ normalized by the DC component $$T(0)=\sum_{n=0}^{M-1}C(m)$$ to allow the representation and comparison of different hierarchical levels of tonal pitch; and $$w_a(k)=\{3, 8, 11.5, 15, 14.5, 7.5\}$$ are weights that regulate the importance of each coefficient (or interpreted musical interval) in $$T(k)$$. The weights are optimized for musical audio and result from empirical ratings of dyads consonance, which adjust the contribution of each dimension $$k$$ of the space (or interpreted musical interval), making it a perceptually relevant space in comparison to its non-weighted version.</p>
<p>The interactive box plot below presents the harmonic descriptorsâ€™ statistics per era and instrumentation. To isolate particular descriptors, double-click in the plot legends. Single clicks add/remove a given descriptors from the plot.</p>
<p>{% include boxplot.html %}</p>
<p>Next, we list the full set of harmonic descriptors adopted in the study and detail their mathematical definition and musical interpretation.</p>
<ul>
<li>
<p><strong>Dissonance (diss)</strong>: provides a perceptually inspired indicator of dissonance, as the normalized as a weighted magnitude of TIV magnitudes subtracted from unity $$1 - \frac{\| T(k)\|}{ \|w_a(k)\|}$$. The descriptor output is in the [0,1] range, where 1 corresponds to a highly dissonant audio (12 pitch class cluster) and 0 to a very consonant audio.</p>
</li>
<li>
<p><strong>Chromaticity (chromatic)</strong>: indicates the level of the chromatic quality of a given audio frame as the magnitude of the TIV in the chromatic pitch circle. It is computed as the magnitude of the T(2) normalized to unity (range [0-1]), $$\frac{\|| T(1)\||}{w_a(1)}$$.</p>
</li>
<li>
<p><strong>Dyadicity (dyad)</strong>: indicates the level to which a given audio frame embeds the tritone quality. High dyadicity values indicate sonorities consisting of stacked perfect and augmented fourths. It is computed as the magnitude of the T(2) normalized to unity (range [0-1]), $$\frac{\|| T(2)\||}{w_a(2)}$$.</p>
</li>
<li>
<p><strong>Triadicity (triad)</strong>: indicates the level to which a given audio frame consists of major and minor triads. It is computed as the magnitude of the T(3) normalized to unity (range [0-1]), $$\frac{\|| T(3)\||}{w_a(3)}$$.</p>
</li>
<li>
<p><strong>Diminished quality (dim)</strong>: indicates the level to which a given audio frame complies to a diminished seventh chord. It is computed as the magnitude of the T(4) normalized to unity (range [0-1]), $$\frac{\|| T(4)\||}{w_a(4)}$$.</p>
</li>
<li>
<p><strong>Diatonicity (diatonic)</strong>: indicates the level of diatonicity of a given audio frame. It is computed as the magnitude of the T(5) normalized to unity (range [0-1]), $$\frac{\|| T(5)\||}{w_a(5)}$$.</p>
</li>
<li>
<p><strong>Whole-toneness (wholeTone)</strong>: indicates the level to which a given audio frame complies to a whole-tone set. It is computed as the magnitude of the T(6) normalized to unity (range [0-1]), $$\frac{\|| T(6)\||}{w_a(6)}$$.</p>
</li>
<li>
<p><strong>HCDF peaks (hcdfPeaks)</strong>: is computed as the magnitude of the peaks from the Harmonic Change Detection Function (HCDF) in the Tonal Interval Space. Larger magnitude values indicate harmonic changes from greater perceptual distance across two sequential chords.</p>
</li>
<li>
<p><strong>Harmonic Rhythm (hRhythm)</strong>: is computed as the inter peak interval (in frames) from the HCDF, thus providing a loose indicator of the harmonic rhythm.</p>
</li>
<li>
<p><strong>Euclidean/Cosine Tonal Dispersion (eucTDispersion and cosTDispersion)</strong>: measures the Euclidean or cosine distance of each audio frame from the tonal center. The tonal center TIV results from the mean per pc bin from a larger musical excerpt (or musical track).</p>
</li>
<li>
<p><strong>Euclidean distance (eucTIV)</strong>: measures the Euclidean distance between consecutive audio frames. It provides a measure of perceptual relatedness, enforcing the interval content relation across TIVs.</p>
</li>
<li>
<p><strong>Cosine distance (cosTIV)</strong>: measures the cosine distance between consecutive audio frames. It provides a measure of the common tone shared across TIVs, roughly related to voice leading.</p>
</li>
</ul>
<h2>Descriptors Analysis</h2>
<p>To assess the intercorrelations among harmonic audio descriptors and the number of groups of independent descriptors, we modeled the between-descriptor distances using two distance models: hierarchical clustering and metric MDS. Distance models are computed from a square matrix denoting the absolute correlation distance across all harmonic audio descriptors.</p>
<img class="img-responsive center" src="/assets/img/dendogram.png" style="max-width: 87%;">
<img class="img-responsive center" src="/assets/img/mds.png">
<h2><br></h2>
<p><strong>Feature importance:</strong> A cross validated logistic regression was performed to rank the importance of each feature in discriminating four historical Western music genres (Baroque, Classical, Romantic, and Modern).</p>
<img class="img-responsive center" src="/assets/img/relative_feature_importance.png" style="max-width: 80%;">